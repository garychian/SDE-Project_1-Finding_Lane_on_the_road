{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "from moviepy.editor import VideoFileClip\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Global parameters\n",
    "# Gaussian smooting\n",
    "kernel_size = 3\n",
    "\n",
    "# Canny Edge Detector\n",
    "low_threshold = 50\n",
    "high_threshold = 150\n",
    "\n",
    "# Refion of interest vertices\n",
    "# we want to trapezoid shape, with bottom edge at the bottom of the image\n",
    "trap_bottom_width = 0.85 # width of bottom edge of trapezoid, expressed as percentage of image width\n",
    "trap_top_width = 0.07    # ditto for top edge of trapezoid\n",
    "trap_height = 0.4        # height of the trapezoid expressed as percentage of image height\n",
    "\n",
    "# Hough Transfer\n",
    "rho = 2 # distance resolution in pixels of Hough grid\n",
    "theta = 1*np.pi/180  # angular resolution in radians of the Hough grid\n",
    "threshold = 15    # minimun number of votes(intersections in Hough grid cell)\n",
    "min_line_length = 10    # minmun number of pixels making up a line\n",
    "max_line_gap = 20      # maxmum gap in pixels between connectable line segments\n",
    "\n",
    "\n",
    "# helper functions \n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "\tThis will return an image with only one color channel\n",
    "\tbut NOTE: to see the returned image as grayscale\n",
    "\tyou should call plt.imshow(gray, cmap='gray')\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img,vertices):\n",
    "    '''\n",
    "    Applies an image mask.\n",
    "    \n",
    "    only keeps the region of the image defined by the polygon formed from `vertices`. The rest \n",
    "    of the image is set to black\n",
    "    '''\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "\t\n",
    "\t#defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "\t\t\n",
    "\t#filling pixels inside the polygon defined by \"vertices\" with the fill color\t\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "\t\n",
    "\t#returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def draw_lines(img,lines,color=[255,0,0],thickness = 10):\n",
    "    # in case of error, don't draw the lines\n",
    "    if lines is None:\n",
    "        return \n",
    "    if len(lines) == 0:\n",
    "        return \n",
    "    draw_right = True\n",
    "    draw_left = True\n",
    "    \n",
    "    # Find slopes of all lines\n",
    "    # But only care about lines where abs(slope) > slope_threshold\n",
    "\n",
    "    slope_threshold = 0.5\n",
    "    slopes = []\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        x1,y1,x2,y2 = line[0] # line= [[x1,y1,x2,y2]]\n",
    "        \n",
    "        # calcuate slope \n",
    "        if x2 - x1 == 0.:# corner casem avoiding division by 0\n",
    "            slope = 999.  # practically infinite slope\n",
    "            \n",
    "        else:\n",
    "            slope = (y2-y1)/(x2-x1)\n",
    "            \n",
    "        # Filter lines based on slope\n",
    "        if abs(slope) > slope_threshold:\n",
    "            slopes.append(slope)\n",
    "            new_lines.append(line)\n",
    "    lines = new_lines\n",
    "    \n",
    "    # Split lines into right_lines and left_lines, representing the right and left lane lines\n",
    "\t# Right/left lane lines must have positive/negative slope, and be on the right/left half of the image\n",
    "    right_lines = []\n",
    "    left_lines = []\n",
    "    for i, line in enumerate(lines):\n",
    "        x1,y1,x2,y2 = line[0]\n",
    "        img_x_center = img.shape[1]/2   # x coordinate of center of image\n",
    "        if slopes[i] > 0 and x1 > img_x_center and x2 > img_x_center:\n",
    "            right_lines.append(line)\n",
    "        elif slopes[i] < 0 and x1 < img_x_center and x2< img_x_center:\n",
    "            left_lines.append(line)\n",
    "            \n",
    "    # Run linear regression to find best fit line for right and left lane lines\n",
    "    right_lines_x = []\n",
    "    right_lines_y = []\n",
    "    \n",
    "    for line in right_lines:\n",
    "        x1,y1,x2,y2 = line[0]\n",
    "        \n",
    "        right_lines_x.append(x1)\n",
    "        right_lines_x.append(x2)\n",
    "        \n",
    "        right_lines_y.append(y1)\n",
    "        right_lines_y.append(y2)\n",
    "        \n",
    "    if len(right_lines_x) > 0:\n",
    "        right_m, right_b = np.polyfit(right_lines_x, right_lines_y,1)  # y = m*x + b\n",
    "    else:\n",
    "        right_m, right_b = 1,1\n",
    "        draw_right = False\n",
    "            \n",
    "    # Left lane lines\n",
    "    left_lines_x = []\n",
    "    left_lines_y = []\n",
    "\t\n",
    "    for line in left_lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "\t\t\n",
    "        left_lines_x.append(x1)\n",
    "        left_lines_x.append(x2)\n",
    "\t\t\n",
    "        left_lines_y.append(y1)\n",
    "        left_lines_y.append(y2)\n",
    "\t\t\n",
    "    if len(left_lines_x) > 0:\n",
    "        left_m, left_b = np.polyfit(left_lines_x, left_lines_y, 1)  # y = m*x + b\n",
    "    else:\n",
    "        left_m, left_b = 1, 1\n",
    "        draw_left = False\n",
    "     \n",
    "    # Find 2 end points for right and left lines, used for drawing the line\n",
    "    # y = m*x + b  --> x = (y-b)/m\n",
    "    y1 = img.shape[0]\n",
    "    y2 = img.shape[0] * (1-trap_height)\n",
    "    \n",
    "    right_x1 = (y1 - right_b)/right_m\n",
    "    right_x2 = (y2 - right_b)/right_m\n",
    "    \n",
    "    left_x1 = (y1 - left_b)/left_m\n",
    "    left_x2 = (y2 - left_b)/left_m\n",
    "    \n",
    "    # Convert calculated end points from float to int\n",
    "    y1 = int(y1)\n",
    "    y2 = int(y2)\n",
    "    right_x1 = int(right_x1)\n",
    "    right_x2 = int(right_x2)\n",
    "    left_x1 = int(left_x1)\n",
    "    left_x2 = int(left_x2)\n",
    "    \n",
    "    # Draw the right and left lines on image\n",
    "    if draw_right:\n",
    "        cv2.line(img,(right_x1,y1),(right_x2,y2),color,thickness)\n",
    "        \n",
    "    if draw_left:\n",
    "        cv2.line(img,(left_x1,y1),(left_x2,y2), color, thickness)\n",
    "        \n",
    "def hough_lines(img,rho,theta,threshold,min_line_len, max_line_gap):\n",
    "    '''\n",
    "    `img` should be the output of a Canny transform\n",
    "    \n",
    "    returns an image with hough lines drawn\n",
    "    '''\n",
    "    lines = cv2.HoughLinesP(img,rho,theta,threshold,np.array([]),minLineLength=min_line_len,maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((*img.shape,3),dtype=np.uint8)   # 3 channel RGB image\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "\n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "\n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "\n",
    "\n",
    "def filter_color(image):\n",
    "    '''\n",
    "    Filter white pixels\n",
    "    '''\n",
    "    white_threshold = 200\n",
    "    lower_white = np.array([white_threshold, white_threshold,white_threshold])\n",
    "    upper_white = np.array([255,255,255])\n",
    "    white_mask = cv2.inRange(image, lower_white, upper_white)\n",
    "    white_image = cv2.bitwise_and(image, image, mask=white_mask)\n",
    "    \n",
    "    # Filter yellow pixels\n",
    "    hsv = cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "    lower_yellow = np.array([90,100,100])\n",
    "    upper_yellow = np.array([100,255,255])\n",
    "    yellow_mask = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "    yellow_image = cv2.bitwise_and(image,image,mask=yellow_mask)\n",
    "    \n",
    "    # Combine the two above images\n",
    "    image2 = cv2.addWeighted(white_image, 1., yellow_image,1.,0.)\n",
    "    \n",
    "    return image2\n",
    "\n",
    "def annotate_image_array(image_in):\n",
    "    '''Given an image Numpy array, return the annotated image as Numpy array'''\n",
    "    # pnly keep white and yellow pixels in the image, all other pixels become black\n",
    "    image = filter_color(image_in)\n",
    "    \n",
    "    \n",
    "    # Read in and grayscale the image\n",
    "    gray = grayscale(image)\n",
    "    \n",
    "    # Apply Gaussian blur\n",
    "    blur_gray = gaussian_blur(gray, kernel_size)\n",
    "    \n",
    "    \n",
    "    # Apply Canny edge detector\n",
    "    edges = canny(blur_gray, low_threshold, high_threshold)\n",
    "    \n",
    "    # Create masked edges using trapezoid-shaped region-of-interest\n",
    "    imshape = image.shape\n",
    "    vertices = np.array([[\\\n",
    "                         ((imshape[1]*(1-trap_bottom_width)) // 2, imshape[0]),\\\n",
    "                         ((imshape[1]*(1-trap_top_width))//2,imshape[0] - imshape[0]*trap_height),\\\n",
    "                         (imshape[1] - (imshape[1]*(1-trap_top_width))//2,imshape[0]*trap_height),\\\n",
    "                         (imshape[1] - (imshape[1] *(1- trap_bottom_width))//2, imshape[0])]]\\\n",
    "                         ,dtype=np.int32)\n",
    "    masked_edges = region_of_interest(edges, vertices)\n",
    "    \n",
    "    # Run Hough on edge detected image\n",
    "    line_image = hough_lines(masked_edges, rho, theta, threshold, min_line_length, max_line_gap)\n",
    "    \n",
    "    # Draw lane lines on the original image\n",
    "    initial_image = image_in.astype('uint8')\n",
    "    annotated_image = weighted_img(line_image, initial_image)\n",
    "    \n",
    "    return annotated_image\n",
    "\n",
    "def annotate_image(input_file, out_file):\n",
    "    '''Given input_file image, save annotated image to output_file'''\n",
    "    annotated_image = annotate_image_array(mpimg.imread(input_file))\n",
    "    plt.imsave(output_file, annotated_image)\n",
    "    \n",
    "def annotate_video(input_file, out_file):\n",
    "    '''Given input_file image, save annotated image to output_file'''\n",
    "    video = VideoFileClip(input_file)\n",
    "    annotated_video = video.fl_image(annotate_image_array)\n",
    "    annotated_video.write_videofile(out_file,audio=False)\n",
    "    \n",
    "# End helper functions       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage: ipykernel_launcher.py [options]\n",
      "\n",
      "ipykernel_launcher.py: error: no such option: -f\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\Self Learning\\Anaconda3\\envs\\tf2.0.0rc1\\lib\\optparse.py\", line 1387, in parse_args\n",
      "    stop = self._process_args(largs, rargs, values)\n",
      "  File \"D:\\Self Learning\\Anaconda3\\envs\\tf2.0.0rc1\\lib\\optparse.py\", line 1431, in _process_args\n",
      "    self._process_short_opts(rargs, values)\n",
      "  File \"D:\\Self Learning\\Anaconda3\\envs\\tf2.0.0rc1\\lib\\optparse.py\", line 1513, in _process_short_opts\n",
      "    raise BadOptionError(opt)\n",
      "optparse.BadOptionError: no such option: -f\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Self Learning\\Anaconda3\\envs\\tf2.0.0rc1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-23-46f85d1394f0>\", line 14, in <module>\n",
      "    options, args = parser.parse_args()\n",
      "  File \"D:\\Self Learning\\Anaconda3\\envs\\tf2.0.0rc1\\lib\\optparse.py\", line 1389, in parse_args\n",
      "    self.error(str(err))\n",
      "  File \"D:\\Self Learning\\Anaconda3\\envs\\tf2.0.0rc1\\lib\\optparse.py\", line 1569, in error\n",
      "    self.exit(2, \"%s: error: %s\\n\" % (self.get_prog_name(), msg))\n",
      "  File \"D:\\Self Learning\\Anaconda3\\envs\\tf2.0.0rc1\\lib\\optparse.py\", line 1559, in exit\n",
      "    sys.exit(status)\n",
      "SystemExit: 2\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Self Learning\\Anaconda3\\envs\\tf2.0.0rc1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\Self Learning\\Anaconda3\\envs\\tf2.0.0rc1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\Self Learning\\Anaconda3\\envs\\tf2.0.0rc1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\Self Learning\\Anaconda3\\envs\\tf2.0.0rc1\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "# main script\n",
    "if __name__ == '__main__':\n",
    "    from optparse import OptionParser\n",
    "    \n",
    "    # Configure command line options\n",
    "    parser = OptionParser()\n",
    "    parser.add_option(\"-i\", \"--input_file\", dest=\"input_file\", help=\"Input video/image file\")\n",
    "    parser.add_option(\"-o\", \"--output_file\", dest=\"output_file\",help=\"Output (destination) video/image file\")\n",
    "    parser.add_option(\"-I\", \"--image_only\",action=\"store_true\", dest=\"image_only\", default=False,\n",
    "                      help=\"Annotate image (defaults to annotating video)\")\n",
    "    \n",
    "    \n",
    "    # Get and parse command line options\n",
    "    options, args = parser.parse_args()\n",
    "    \n",
    "    input_file = options.input_file\n",
    "    output_file = options.output_file\n",
    "    image_only = options.image_only\n",
    "    \n",
    "    if image_only:\n",
    "        annotate_image(input_file, output_file)\n",
    "        \n",
    "    else:\n",
    "        annotate_video(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
